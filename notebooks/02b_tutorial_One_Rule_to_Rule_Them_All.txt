#| hide
#skip
! [ -e /content ] && pip install -Uqq pyndamics3 emcee # upgrade pyndamics3 on colab

%matplotlib inline
from pylab import *
from sie.core import *

def plot_distribution(dist,label=r'\bar{x}',fill_left=None,xlim=None):
    import pylab as py
    qmin=.0001
    qmax=1-qmin

    if xlim is None:
        xmin=dist.D.ppf(qmin)
        xmax=dist.D.ppf(qmax)
    else:
        xmin,xmax=xlim

    x=linspace(xmin,xmax,200)
    y=dist.D.pdf(x)

    figure(figsize=(16,5))

    plot(x,y)

    v=dist.D.ppf([2.5/100,50/100,97.5/100])
    label=label
    py.title(r'$\hat{%s}^{97.5}_{2.5}=%.3f^{%.3f}_{%.3f}$' % (label,v[1],v[2],v[0]))
    py.ylabel(r'$p(%s|{\rm true\,\, value})$' % label)
    py.xlabel(r'$%s$' % label)

    if fill_left:
        x1=x.min()
        x2=fill_left
        xf=linspace(x1,x2,100)
        yf=dist.D.pdf(xf)
        fill_between(xf,yf,facecolor='red', alpha=0.2)   
        plot(xf,yf,'r-')    
        text(x.min(),0.2,'area = %.4f' % dist.D.cdf(x2))

from sie.mcmc import StatsModel

from sie.distributions import Normal

x=[12,14,16]
σ=1
N=len(x)
dist=Normal(mean=mean(x),std=σ/sqrt(N))

plot_distribution(dist,fill_left=13)

x=array([12,14,16])
model=StatsModel()
model.add_data(x=x)
model.add("μ ~ Normal(0,50)")  # really broad prior
model.add("x ~ Normal(μ,1)")


model.run_mcmc(1000)
model.plot_chains()  # this is for debugging/making sure things are working

model.plot_distributions()
text(11.5,.4,f"P(μ<13)={model.P('μ<13'):.3}")

model.P("μ<13")

from sie.distributions import StudentT

x=[12,14,16]
dof=len(x)

dist=StudentT(mean=mean(x),
              std=std(x)/sqrt(N-1),
              dof=N-1)

plot_distribution(dist,fill_left=13,xlim=[9,19])

x=array([12,14,16])
model=StatsModel()
model.add_data(x=x)
model.add("μ ~ Uniform(-50,50)")  # really broad prior
model.add("σ ~ Jeffreys()")
model.add("x ~ Normal(μ,σ)")


model.run_mcmc(2000,repeat=2)
#model.plot_chains()

model.plot_distributions('μ',xlim={'μ':[0,25],'σ':[0,30]})
text(2,.1,f"P(μ<13)={model.P('μ<13'):.3}")

model.plot_distributions('σ',xlim={'μ':[0,25],'σ':[0,30]})
text(7.5,.1,f"P(σ>5)={model.P('σ>5'):.3}")

x=array([12,14,16])
model=StatsModel()
model.add_data(x=x)
model.add("μ ~ Uniform(-50,50)")  # really broad prior
model.add("γ ~ Jeffreys()")
model.add("x ~ Cauchy(μ,γ)")


model.run_mcmc(2000,repeat=2)
#model.plot_chains()

model.plot_distributions('μ',xlim={'μ':[0,25],'σ':[0,30]})
text(2,.1,f"P(μ<13)={model.P('μ<13'):.3}")

x=array([12,14,16])
model=StatsModel()
model.add_data(x=x)
model.add("θ ~ Uniform(-50,50)")  # really broad prior
model.add("x ~ Exponential(1,offset=θ)")



# model.run_mcmc(2000,repeat=2)
# model.plot_chains()

xy1="""
X	Y
10	8.04
8	6.95
13	7.58
9	8.81
11	8.33
14	9.96
6	7.24
4	4.26
12	10.84
7	4.82
5	5.68
"""

xy2="""
X	Y
10	9.14
8	8.14
13	8.74
9	8.77
11	9.26
14	8.1
6	6.13
4	3.1
12	9.13
7	7.26
5	4.74
"""

xy3="""
X	Y
10	7.46
8	6.77
13	12.74
9	7.11
11	7.81
14	8.84
6	6.08
4	5.39
12	8.15
7	6.42
5	5.73
"""

xy4="""
X	Y
8	6.58
8	5.76
8	7.71
8	8.84
8	8.47
8	7.04
8	5.25
19	12.5
8	5.56
8	7.91
8	6.89
"""

for i,xy in enumerate([xy1,xy2,xy3,xy4]):
    subplot(2,2,i+1)
    x,y=array([_.split() for _ in xy.strip().split('\n')[1:]],dtype=float).T
    plot(x,y,'o')    

xy=xy1
x,y=array([_.split() for _ in xy.strip().split('\n')[1:]],dtype=float).T


model=StatsModel()
model.add_data(x=x,y=y)
model.add("m ~ Normal(0,10)")
model.add("b ~ Normal(0,10)")
model.add("σ ~ Jeffreys()")
model.add("y ~ Normal(m*x+b,σ)")
model

model.run_mcmc(800,repeat=3)
model.plot_chains()

figure(figsize=(12,12))
for i,xy in enumerate([xy1,xy2,xy3,xy4]):
    subplot(2,2,i+1)
    x,y=array([_.split() for _ in xy.strip().split('\n')[1:]],dtype=float).T
    
    data=x,y
    model=StatsModel()
    model.add_data(x=x,y=y)
    model.add("m ~ Normal(0,10)")
    model.add("b ~ Normal(0,10)")
    model.add("σ ~ Jeffreys()")
    model.add("y ~ Normal(m*x+b,σ)"               )
    
    model.run_mcmc(800,repeat=2)
    
    
    plot(x,y,'o')    
    xl=gca().get_xlim()
    xx=linspace(xl[0],xl[1],100)
    
    for m,b in model.sample_iterator('m','b'):
        yy=m*xx+b
        plot(xx,yy,'g-',alpha=0.002)

    m,b=model.best_estimates()['m'][1],model.best_estimates()['b'][1]
    yy=m*xx+b
    plot(xx,yy,'g-')
    
    S=[]
    for key,label in zip(['m','b'],['m','b']):
        v=model.best_estimates()[key].ravel()
        S.append(r'$\hat{%s}^{97.5}_{2.5}=%.3f^{%.3f}_{%.3f}$' % (label,v[1],v[2],v[0]))

    title(",".join(S),fontsize=12)
    
    

figure(figsize=(12,12))
for i,xy in enumerate([xy1,xy2,xy3,xy4]):
    subplot(2,2,i+1)
    x,y=array([_.split() for _ in xy.strip().split('\n')[1:]],dtype=float).T
    
    data=x,y
    model=StatsModel()
    model.add_data(x=x,y=y)
    model.add("m ~ Normal(0,10)")
    model.add("b ~ Normal(0,10)")
    model.add("σ ~ Jeffreys()")
    model.add("ν ~ Exponential(29,offset=1)")
    model.add("y ~ StudentT(ν,m*x+b,σ)"               )
    
    model.run_mcmc(800,repeat=2)
    
    
    plot(x,y,'o')    
    xl=gca().get_xlim()
    xx=linspace(xl[0],xl[1],100)
    
    for m,b in model.sample_iterator('m','b'):
        yy=m*xx+b
        plot(xx,yy,'g-',alpha=0.002)

    m,b=model.best_estimates()['m'][1],model.best_estimates()['b'][1]
    yy=m*xx+b
    plot(xx,yy,'g-')
    
    S=[]
    for key,label in zip(['m','b'],['m','b']):
        v=model.best_estimates()[key].ravel()
        S.append(r'$\hat{%s}^{97.5}_{2.5}=%.3f^{%.3f}_{%.3f}$' % (label,v[1],v[2],v[0]))

    title(",".join(S),fontsize=12)
    
    


