[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "sie",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "sie"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "sie",
    "section": "Install",
    "text": "Install\npip install sie",
    "crumbs": [
      "sie"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "sie",
    "section": "How to use",
    "text": "How to use\nMore later!\n\n1+1\n\n2",
    "crumbs": [
      "sie"
    ]
  },
  {
    "objectID": "02a_tutorial_BEST.html",
    "href": "02a_tutorial_BEST.html",
    "title": "Tutorial: BEST Test",
    "section": "",
    "text": "from pylab import *\n\n\nfrom sie.mcmc import StatsModel\n\n\ndrug = (101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,\n        109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,\n        96,103,124,101,101,100,101,101,104,100,101)\nplacebo = (99,101,100,101,102,100,97,101,104,101,102,102,100,105,88,101,100,\n           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,\n           101,100,99,101,100,102,99,100,99)\n\n\nmodel=StatsModel()\nmodel.add_data(drug=drug,placebo=placebo)\n\nmodel.add(\"μ_drug ~ Normal(M,1000*S)\")\nmodel.add(\"μ_placebo ~ Normal(M,1000*S)\")\nmodel.add(\"σ_drug ~ Uniform(mn,mx)\")\nmodel.add(\"σ_placebo ~ Uniform(mn,mx)\")\nmodel.add(\"ν ~ Exponential(29,offset=1)\")\nmodel.add(\"res_drug ~ StudentT(ν,drug-μ_drug,σ_drug,sum=True)\")\nmodel.add(\"res_placebo ~ StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)\")\n\npooled=np.concatenate([drug,placebo])\nS=mean(pooled)\nM=std(pooled)                      \nmodel.extra(S=S,M=M,mn=0.001*S,mx=1000*S)\n\nmodel.initialize()\nmodel\n\n\nParameters\n----------\n    {'μ_drug': μ_drug, 'μ_placebo': μ_placebo, 'σ_drug': σ_drug, 'σ_placebo': σ_placebo, 'ν': ν, 'res_drug': res_drug, 'res_placebo': res_placebo}\nExtra\n-----\n    ['S', 'M', 'mn', 'mx']\nData\n----\n    ['drug', 'placebo']\nPrior\n-----\n    ['μ_drug ~ Normal(M,1000*S)', 'μ_placebo ~ Normal(M,1000*S)', 'σ_drug ~ Uniform(mn,mx)', 'σ_placebo ~ Uniform(mn,mx)', 'ν ~ Exponential(29,offset=1)']\nLikelihood\n----------\n    ['res_drug ~ StudentT(ν,drug-μ_drug,σ_drug,sum=True)', 'res_placebo ~ StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)']\n        \n\n\n\nprint(model.make_func())\n\ndef _lnprior(θ,slices,extra={}):\n    S=extra['S']\n    M=extra['M']\n    mn=extra['mn']\n    mx=extra['mx']\n    μ_drug=θ[slices.μ_drug]\n    μ_placebo=θ[slices.μ_placebo]\n    σ_drug=θ[slices.σ_drug]\n    σ_placebo=θ[slices.σ_placebo]\n    ν=θ[slices.ν]\n\n    _value=0\n\n    _value+=Normal(M,1000*S)(μ_drug)\n    _value+=Normal(M,1000*S)(μ_placebo)\n    _value+=Uniform(mn,mx)(σ_drug)\n    _value+=Uniform(mn,mx)(σ_placebo)\n    _value+=Exponential(29,offset=1)(ν)\n\n    return _value\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    S=extra['S']\n    M=extra['M']\n    mn=extra['mn']\n    mx=extra['mx']\n    drug=data['drug']\n    placebo=data['placebo']\n\n    μ_drug=θ[slices.μ_drug]\n    μ_placebo=θ[slices.μ_placebo]\n    σ_drug=θ[slices.σ_drug]\n    σ_placebo=θ[slices.σ_placebo]\n    ν=θ[slices.ν]\n\n    res_drug=θ[slices.res_drug]\n    res_placebo=θ[slices.res_placebo]\n\n    _value=0\n\n    _value+=StudentT(ν,drug-μ_drug,σ_drug,sum=True)(res_drug)\n    _value+=StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)(res_placebo)\n\n    return _value.sum()\n\n\n\n\nmodel.run_mcmc(800,repeat=3)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.45 s\nRunning MCMC 1/3...\nemcee: Exception while calling your likelihood function:\n  params: [-1.24867775e+11  9.26959268e+11  1.69545800e+16 -8.11699203e+16\n -3.59686916e+15 -1.01092260e+17  5.15261995e+16]\n  args: []\n  kwargs: {}\n  exception:\n\n\n/Users/bblais/Documents/Git/sie/sie/mcmc.py:177: RuntimeWarning: invalid value encountered in log\n  values=N*(gammaln((df+1)/2.0)-0.5*log(df*np.pi)-gammaln(df/2.0)-np.log(sd))+(-(df+1)/2.0)*np.log(1+t**2/df)\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/work/lib/python3.11/site-packages/emcee/ensemble.py\", line 624, in __call__\n    return self.f(x, *self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bblais/Documents/Git/sie/sie/mcmc.py\", line 565, in __call__\n    return self._lnposterior(θ)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bblais/Documents/Git/sie/sie/mcmc.py\", line 560, in _lnposterior\n    _value+=self._lnlikelihood(θ,self.data,self.slices,self.extra_params)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;string&gt;\", line 42, in _lnlikelihood\n  File \"/Users/bblais/Documents/Git/sie/sie/mcmc.py\", line 180, in _StudentT\n    raise ValueError('NaN in StudentT',df,mu,sd)\nValueError: ('NaN in StudentT', array([-3.59686916e+15]), array([1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11]), array([1.695458e+16]))\n\n\nValueError: ('NaN in StudentT', array([-3.59686916e+15]), array([1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11, 1.24867775e+11,\n       1.24867775e+11, 1.24867775e+11, 1.24867775e+11]), array([1.695458e+16]))\n\n\n\nprint(model.make_func())",
    "crumbs": [
      "Tutorial: BEST Test"
    ]
  },
  {
    "objectID": "01_mcmc.html",
    "href": "01_mcmc.html",
    "title": "MCMC part of the libary",
    "section": "",
    "text": "source",
    "crumbs": [
      "MCMC part of the libary"
    ]
  },
  {
    "objectID": "01_mcmc.html#distribution-log-likelihoods",
    "href": "01_mcmc.html#distribution-log-likelihoods",
    "title": "MCMC part of the libary",
    "section": "Distribution Log Likelihoods",
    "text": "Distribution Log Likelihoods\n\nsource\n\ninit_Jeffreys\n\n init_Jeffreys (sum=False)\n\n\nsource\n\n\nJeffreys\n\n Jeffreys ()\n\n\nsource\n\n\ninit_HalfNormal\n\n init_HalfNormal (μ, σ, sum=False)\n\n\nsource\n\n\nHalfNormal\n\n HalfNormal (μ, σ, sum=False)\n\n\nsource\n\n\ninit_StudentT\n\n init_StudentT (μ, σ, sum=False)\n\n\nsource\n\n\nStudentT\n\n StudentT (df, mu, sd, sum=False)\n\n\nsource\n\n\ninit_Exponential\n\n init_Exponential (scale, offset=0, sum=False)\n\n\nsource\n\n\nExponential\n\n Exponential (scale, offset=0, sum=False)\n\n\nsource\n\n\ninit_Uniform\n\n init_Uniform (mn, mx, sum=False)\n\n\nsource\n\n\nUniform\n\n Uniform (mn, mx, sum=False)\n\n\nsource\n\n\ninit_Normal\n\n init_Normal (μ, σ, sum=True)\n\n\nsource\n\n\nNormal\n\n Normal (μ, σ, sum=True)",
    "crumbs": [
      "MCMC part of the libary"
    ]
  },
  {
    "objectID": "01_mcmc.html#main-mcmc-definitions",
    "href": "01_mcmc.html#main-mcmc-definitions",
    "title": "MCMC part of the libary",
    "section": "Main MCMC Definitions",
    "text": "Main MCMC Definitions\n\nsource\n\nStatsModel\n\n StatsModel ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nParameter\n\n Parameter (eqn, initial_value=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nStatsModel.make_func\n\n StatsModel.make_func ()",
    "crumbs": [
      "MCMC part of the libary"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "sie - Statistical Inference for Everyone",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()",
    "crumbs": [
      "sie - Statistical Inference for Everyone"
    ]
  },
  {
    "objectID": "99_debug_mcmc.html",
    "href": "99_debug_mcmc.html",
    "title": "sie",
    "section": "",
    "text": "# default_exp no_export\n\n\n\nfrom pylab import *\nfrom sie.mcmc import StatsModel\n\n\nx=array([ .2, 0.39595125,   0.22981019,  -4.38971186,   4.57653843,\n         4.38800312,  -3.14227423,  -1.66494169,  -4.0148864 ,\n         4.10562856,   2.19091249,  11.18389772,   1.53046862,\n        -6.05251134,  -1.5028012 ,   1.12985659,   0.84215301,\n        -4.37528332,  -1.51364766,  -6.06991254,  -1.11838459,\n         3.94521945,   3.65019148,  -0.5446649 ,   0.85721735,\n         1.41391355,   1.43089269,   0.6089257 ,   5.03635336,\n         4.92170115,   4.2066542 ,   2.48580373,   9.2895543 ,\n         2.92144036,   2.91079341,   0.55777809,   8.04122751,\n       -12.06833542,  -0.70706651,  14.96419495,   0.82773164,\n         6.32229804,   6.71565991,   5.57064652,   4.87913438,\n        -0.39353282,  -4.45373509,  -3.54839884,   5.38362984,\n         4.70926759,   3.65790252,   0.63145437,   5.24971408,\n         8.2553935 ,   4.79006995,  -8.33670551,  -4.61956851,\n        -4.83453087,   1.62173756,  -1.92585591,  -2.63973241,\n         4.1506629 ,   3.56013401,  13.35631639,  -5.52537233,\n        -1.49474565,  -2.07293056,   5.4540973 ,   2.97490357,\n         4.6955487 ,   0.82952536,  -5.67363532,   9.0946318 ,\n        -2.52705592,   4.10840195,  -3.08773704,  -4.35166723,\n         9.03615482,   4.83026807,  -2.86675068,   2.70522369,\n        13.07522118,  -5.78459681,   3.28781511,   4.80430383,\n         2.27368715,  -7.48890544,   0.47985461,  17.22158394,\n         2.85875906, -12.35840458,   1.67710649,  -0.37967208,\n        -5.64580007,  -3.87064346,   4.78512975,  12.36217118,\n         1.75239768,   2.77851485,  -2.17896821,   6.25559514])\n\n\nlen(x)\n\n101\n\n\n\nmodel=StatsModel()\nmodel.add_data(x=x)\nmodel.add(\"m ~ Normal(0,10)\")\nmodel.add(\"x ~ Normal(m,1)\")\nmodel.initialize()\n\n\nprint(model.make_func())\n\ndef _lnprior(θ,slices,extra={}):\n    m=θ[slices.m]\n\n    _value=0\n\n    _value+=Normal(0,10)(m)\n\n    return _value\n\n\ndef _init_prior(nwalkers,ndim,data,slices,extra={}):\n    x=data['x']\n\n    _pos=np.zeros((nwalkers,ndim))\n    m=_pos[:,slices.m]=init_Normal(0,10)(nwalkers)\n\n    return _pos\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    x=data['x']\n\n    m=θ[slices.m]\n\n\n    _value=0\n\n    _value+=Normal(m,1)(x)\n\n    return _value.sum()\n\n\n\n\nmodel.run_mcmc(800,repeat=3)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.19 s\nRunning MCMC 1/3...\nDone.\n0.95 s\nSamples\nRunning MCMC 2/3...\nDone.\n0.94 s\nSamples\nRunning MCMC 3/3...\nDone.\n0.93 s\nSamples\nfigsize [6.4, 4.0]\n\n\n\n\n\n\n\n\n\n\nmodel.initial_pos.shape\n\n(100, 1)\n\n\n\nraise ValueError\n\nValueError: \n\n\n\nself=model\nθ=self.initial_pos[0,:]\nθ,self._lnprior(θ,self.slices,self.extra_params),self._lnlikelihood(θ,self.data,self.slices,self.extra_params)\n\n\nhist(self.initial_pos)\n\n\nxy1=\"\"\"\nX   Y\n10  8.04\n8   6.95\n13  7.58\n9   8.81\n11  8.33\n14  9.96\n6   7.24\n4   4.26\n12  10.84\n7   4.82\n5   5.68\n\"\"\"\nxy=xy1\nx,y=array([_.split() for _ in xy.strip().split('\\n')[1:]],dtype=float).T\nx,y\n\n(array([10.,  8., 13.,  9., 11., 14.,  6.,  4., 12.,  7.,  5.]),\n array([ 8.04,  6.95,  7.58,  8.81,  8.33,  9.96,  7.24,  4.26, 10.84,\n         4.82,  5.68]))\n\n\n\nmodel=StatsModel()\nmodel.add_data(x=x,y=y)\nmodel.add(\"m ~ Normal(0,10)\")\nmodel.add(\"b ~ Normal(0,10)\")\nmodel.add(\"y ~ Normal(m*x+b,1)\")\nmodel.initialize()\n\n\n# model=StatsModel()\n# model.add_data(x=x,y=y)\n# model.add(\"m ~ Normal(0,10)\")\n# model.add(\"b ~ Normal(0,10)\")\n# model.add(\"σ ~ Jeffreys()\")\n# model.add(\"res ~ Normal(m*x+b-y,σ,sum=True)\")\n# model.initialize()\n# model\n\n\nprint(model.make_func())\n\ndef _lnprior(θ,slices,extra={}):\n    m=θ[slices.m]\n    b=θ[slices.b]\n\n    _value=0\n\n    _value+=Normal(0,10)(m)\n    _value+=Normal(0,10)(b)\n\n    return _value\n\n\ndef _init_prior(nwalkers,ndim,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    _pos=np.zeros((nwalkers,ndim))\n    m=_pos[:,slices.m]=init_Normal(0,10)(nwalkers)\n    b=_pos[:,slices.b]=init_Normal(0,10)(nwalkers)\n\n    return _pos\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    m=θ[slices.m]\n    b=θ[slices.b]\n\n\n    _value=0\n\n    _value+=Normal(m*x+b,1)(y)\n\n    return _value.sum()\n\n\n\n\nmodel.run_mcmc(800,repeat=3)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.30 s\nRunning MCMC 1/3...\nDone.\n1.33 s\nSamples\nRunning MCMC 2/3...\nDone.\n1.32 s\nSamples\nRunning MCMC 3/3...\nDone.\n1.33 s\nSamples\nfigsize [6.4, 8.0]\n\n\n\n\n\n\n\n\n\n\nself=model\nargs=[key for key in self.parameters if len(self.parameters[key])==1]\nresult={}\nfor key in args:\n    s=self.slices.__getattribute__(key)\n    sub_sample=self.samples[:,s]\n    result[key]=np.percentile(sub_sample,[16,50,84],axis=0)\n\n\nresult\n\n{'m': array([[0.41014988],\n        [0.50540031],\n        [0.59880641]]),\n 'b': array([[2.05559951],\n        [2.95931034],\n        [3.85147497]])}\n\n\n\nmodel.plot_distributions()\n\n[('m', 0, array([0.3234603 , 0.50540031, 0.69142507])),\n ('b', 0, array([1.1870701 , 2.95931034, 4.70133465]))]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprint(model.make_func())\n\n\nraise ValueError\n\n\nx,y\n\n(array([10.,  8., 13.,  9., 11., 14.,  6.,  4., 12.,  7.,  5.]),\n array([ 8.04,  6.95,  7.58,  8.81,  8.33,  9.96,  7.24,  4.26, 10.84,\n         4.82,  5.68]))\n\n\n\nmodel=StatsModel()\nmodel.add_data(x=x,y=y)\nmodel.add(\"m ~ Normal(0,10)\")\nmodel.add(\"b ~ Normal(0,10)\")\nmodel.add(\"σ ~ Jeffreys()\")\nmodel.add(\"y ~ Normal(m*x+b,σ)\")  \nmodel.initialize()\n\n\nprint(model.make_func())\n\ndef _lnprior(θ,slices,extra={}):\n    m=θ[slices.m]\n    b=θ[slices.b]\n    σ=θ[slices.σ]\n\n    _value=0\n\n    _value+=Normal(0,10)(m)\n    _value+=Normal(0,10)(b)\n    _value+=Jeffreys()(σ)\n\n    return _value\n\n\ndef _init_prior(nwalkers,ndim,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    _pos=np.zeros((nwalkers,ndim))\n    m=_pos[:,slices.m]=init_Normal(0,10)(nwalkers)\n    b=_pos[:,slices.b]=init_Normal(0,10)(nwalkers)\n    σ=_pos[:,slices.σ]=init_Jeffreys()(nwalkers)\n\n    return _pos\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    m=θ[slices.m]\n    b=θ[slices.b]\n    σ=θ[slices.σ]\n\n\n    _value=0\n\n    _value+=Normal(m*x+b,σ)(y)\n\n    return _value.sum()\n\n\n\n\nmodel.run_mcmc(800,repeat=3)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.36 s\nRunning MCMC 1/3...\nDone.\n1.60 s\nSamples\nRunning MCMC 2/3...\nDone.\n1.61 s\nSamples\nRunning MCMC 3/3...\nDone.\n1.64 s\nSamples\nfigsize [6.4, 12.0]\n\n\n\n\n\n\n\n\n\n\nself=model\nθ=self.initial_pos[:20,:]\nθ\n\narray([[-14.726862,  -2.881727,   1.145552],\n       [  8.531632,   0.685361,   0.872754],\n       [ 16.336694, -15.209931,   0.698796],\n       [  9.78161 , -12.341471,   0.377232],\n       [ -2.776358,  13.552778,   1.242028],\n       [  1.060544,  -6.029887,   0.708603],\n       [-10.605965,  14.928011,   0.964605],\n       [ -4.620638,   4.434791,   0.529033],\n       [ 12.282724,  -4.594871,   1.543504],\n       [  7.518043,  10.281135,   1.942945],\n       [ -2.968734,  -0.822276,   1.960529],\n       [-14.720863,  -4.546646,   1.493483],\n       [  4.680451,   4.537066,   0.825135],\n       [ 23.6882  ,  -1.853356,   0.035843],\n       [ -4.423048,  -2.939452,   1.590533],\n       [ -4.26002 ,  -7.994485,   1.931194],\n       [ -8.239802,  -8.404516,   1.91273 ],\n       [-20.471723,  -5.985963,   1.72975 ],\n       [  0.197142,  15.275296,   1.393157],\n       [  2.190642,  -0.307717,   0.447838]])\n\n\n\narr=self.initial_pos[:20,:]-array([.1,.1,.1])\narr\n\narray([[-14.826862,  -2.981727,   1.045552],\n       [  8.431632,   0.585361,   0.772754],\n       [ 16.236694, -15.309931,   0.598796],\n       [  9.68161 , -12.441471,   0.277232],\n       [ -2.876358,  13.452778,   1.142028],\n       [  0.960544,  -6.129887,   0.608603],\n       [-10.705965,  14.828011,   0.864605],\n       [ -4.720638,   4.334791,   0.429033],\n       [ 12.182724,  -4.694871,   1.443504],\n       [  7.418043,  10.181135,   1.842945],\n       [ -3.068734,  -0.922276,   1.860529],\n       [-14.820863,  -4.646646,   1.393483],\n       [  4.580451,   4.437066,   0.725135],\n       [ 23.5882  ,  -1.953356,  -0.064157],\n       [ -4.523048,  -3.039452,   1.490533],\n       [ -4.36002 ,  -8.094485,   1.831194],\n       [ -8.339802,  -8.504516,   1.81273 ],\n       [-20.571723,  -6.085963,   1.62975 ],\n       [  0.097142,  15.175296,   1.293157],\n       [  2.090642,  -0.407717,   0.347838]])\n\n\n\nfor θ in array([[-14.826862,  -2.981727,   1.045552],\n       [  8.431632,   0.585361,   0.772754],\n       [ 16.236694, -15.309931,   0.598796],\n       [  9.68161 , -12.441471,   0.277232],\n       [ -2.876358,  13.452778,   1.142028],\n       [  0.960544,  -6.129887,   0.608603],\n       [-10.705965,  14.828011,   0.864605],\n       [ -4.720638,   4.334791,   0.429033],\n       [ 12.182724,  -4.694871,   1.443504],\n       [  7.418043,  10.181135,   1.842945],\n       [ -3.068734,  -0.922276,   1.860529],\n       [-14.820863,  -4.646646,   1.393483],\n       [  4.580451,   4.437066,   0.725135],\n       [ 23.5882  ,  -1.953356,  -0.064157],\n       [ -4.523048,  -3.039452,   1.490533],\n       [ -4.36002 ,  -8.094485,   1.831194],\n       [ -8.339802,  -8.504516,   1.81273 ],\n       [-20.571723,  -6.085963,   1.62975 ],\n       [  0.097142,  15.175296,   1.293157],\n       [  2.090642,  -0.407717,   0.347838]]):\n\n    print(self._lnprior(array(θ),self.slices,self.extra_params),self._lnlikelihood(θ,self.data,self.slices,self.extra_params))\n\n[-7.631224891362969] -116159.3398274462\n[-6.542428059151197] -49697.414471604956\n[-8.420334042283727] -271329.38395385613\n[-6.402765538363496] -383453.39490697236\n[-7.5221062380267165] -2289.2331150895484\n[-6.138948937255586] -470.29672683154485\n[-7.97000271263989] -67655.12462587257\n[-5.802199993165438] -70463.07150370153\n[-7.662423632391141] -28827.103612389965\n[-7.847826447182335] -8771.080643876656\n[-7.115246715202897] -2454.6368966886225\n[-7.981100116335646] -66795.8851901681\n[-6.324990248090959] -17058.520840343204\n-inf -62101104.17347309\n[-6.990662184862778] -7288.9677451029\n[-7.47066777458644] -5505.819819024542\n[-7.7472766976124685] -15373.11331653471\n[-9.232647545350439] -91149.35291723192\n[-7.851628994142052] -392.1112683348964\n[-5.40971391318287] -6598.237813045524\n\n\n\n\n\n0.4607162456260625\n\n\n\nnp.set_printoptions(precision=20)\nθ\n\narray([ 2.090642, -0.407717,  0.347838])\n\n\n\nfrom fastcore.quarto import nbdev_docs\n\nModuleNotFoundError: No module named 'fastcore.quarto'"
  },
  {
    "objectID": "02_tutorial_mcmc.html",
    "href": "02_tutorial_mcmc.html",
    "title": "Tutorial: MCMC",
    "section": "",
    "text": "from pylab import *\n\n\nfrom sie.mcmc import StatsModel\n\n\nx=randn(100)*5+1.2\nmodel=StatsModel()\nmodel.add_data(x=x)\nmodel.add(\"m ~ Normal(0,10)\")\nmodel.add(\"x ~ Normal(m,1)\")\nmodel.initialize()\n\n\nmodel.run_mcmc(800,repeat=2)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.17 s\nRunning MCMC 1/2...\nDone.\n0.95 s\nSamples\nRunning MCMC 2/2...\nDone.\n0.96 s\nSamples\nfigsize [6.4, 4.0]\n\n\n\n\n\n\n\n\n\n\nprint(model.function_str)\n\ndef _lnprior(θ,slices,extra={}):\n    m=θ[slices.m]\n\n    _value=0\n\n    _value+=Normal(0,10)(m)\n\n    return _value\n\n\ndef _init_prior(nwalkers,ndim,data,slices,extra={}):\n    x=data['x']\n\n    _pos=np.zeros((nwalkers,ndim))\n    m=_pos[:,slices.m]=init_Normal(0,10)(nwalkers)\n\n    return _pos\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    x=data['x']\n\n    m=θ[slices.m]\n\n\n    _value=0\n\n    _value+=Normal(m,1)(x)\n\n    return _value.sum()\n\n\n\n\nmodel.plot_distributions()\n\n\n\n\n\n\n\n\n\nxy1=\"\"\"\nX   Y\n10  8.04\n8   6.95\n13  7.58\n9   8.81\n11  8.33\n14  9.96\n6   7.24\n4   4.26\n12  10.84\n7   4.82\n5   5.68\n\"\"\"\nxy=xy1\nx,y=array([_.split() for _ in xy.strip().split('\\n')[1:]],dtype=float).T\nx,y\n\n(array([10.,  8., 13.,  9., 11., 14.,  6.,  4., 12.,  7.,  5.]),\n array([ 8.04,  6.95,  7.58,  8.81,  8.33,  9.96,  7.24,  4.26, 10.84,\n         4.82,  5.68]))\n\n\n\nmodel=StatsModel()\nmodel.add_data(x=x,y=y)\nmodel.add(\"m ~ Normal(0,10)\")\nmodel.add(\"b ~ Normal(0,10)\")\nmodel.add(\"σ ~ Jeffreys()\")\nmodel.add(\"y ~ Normal(m*x+b,σ)\")\nmodel.initialize()\nmodel\n\n\nParameters\n----------\n    {'m': m, 'b': b, 'σ': σ}\nExtra\n-----\n    []\nData\n----\n    ['x', 'y']\nPrior\n-----\n    ['m ~ Normal(0,10)', 'b ~ Normal(0,10)', 'σ ~ Jeffreys()']\nLikelihood\n----------\n    []\nData Parameters\n---------------\n    ['y ~ Normal(m*x+b,σ)']\n        \n\n\n\nprint(model.function_str)\n\ndef _lnprior(θ,slices,extra={}):\n    m=θ[slices.m]\n    b=θ[slices.b]\n    σ=θ[slices.σ]\n\n    _value=0\n\n    _value+=Normal(0,10)(m)\n    _value+=Normal(0,10)(b)\n    _value+=Jeffreys()(σ)\n\n    return _value\n\n\ndef _init_prior(nwalkers,ndim,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    _pos=np.zeros((nwalkers,ndim))\n    m=_pos[:,slices.m]=init_Normal(0,10)(nwalkers)\n    b=_pos[:,slices.b]=init_Normal(0,10)(nwalkers)\n    σ=_pos[:,slices.σ]=init_Jeffreys()(nwalkers)\n\n    return _pos\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    x=data['x']\n    y=data['y']\n\n    m=θ[slices.m]\n    b=θ[slices.b]\n    σ=θ[slices.σ]\n\n\n    _value=0\n\n    _value+=Normal(m*x+b,σ)(y)\n\n    return _value.sum()\n\n\n\n\nmodel.run_mcmc(800,repeat=3)\nmodel.plot_chains()\n\nSampling Prior...\nDone.\n0.35 s\nRunning MCMC 1/3...\nDone.\n1.65 s\nSamples\nRunning MCMC 2/3...\nDone.\n1.65 s\nSamples\nRunning MCMC 3/3...\nDone.\n1.63 s\nSamples\nfigsize [6.4, 12.0]\n\n\n\n\n\n\n\n\n\n\nmodel.best_estimates()\n\n{'m': array([[0.38177648],\n        [0.506196  ],\n        [0.63155887]]),\n 'b': array([[1.74719792],\n        [2.94023431],\n        [4.1315828 ]]),\n 'σ': array([[1.01934395],\n        [1.27166633],\n        [1.65870712]])}\n\n\n\nmodel.plot_chains('σ')\n\nfigsize [6.4, 4.0]\n\n\n\n\n\n\n\n\n\n\nmodel.plot_distributions()\n\n[('m', 0, array([0.23545037, 0.506196  , 0.78234975])),\n ('b', 0, array([0.33890936, 2.94023431, 5.47363412])),\n ('σ', 0, array([0.84764841, 1.27166633, 2.29336744]))]",
    "crumbs": [
      "Tutorial: MCMC"
    ]
  },
  {
    "objectID": "99_debug_BEST.html",
    "href": "99_debug_BEST.html",
    "title": "sie",
    "section": "",
    "text": "from pylab import *\n\n\n\nfrom sie.mcmc import StatsModel\n\n\ndrug = (101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,\n        109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,\n        96,103,124,101,101,100,101,101,104,100,101)\nplacebo = (99,101,100,101,102,100,97,101,104,101,102,102,100,105,88,101,100,\n           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,\n           101,100,99,101,100,102,99,100,99)\n\n\nmodel=StatsModel()\nmodel.add_data(drug=drug,placebo=placebo)\n\nmodel.add(\"μ_drug ~ Normal(M,1000*S)\")\nmodel.add(\"μ_placebo ~ Normal(M,1000*S)\")\nmodel.add(\"σ_drug ~ Uniform(mn,mx)\")\nmodel.add(\"σ_placebo ~ Uniform(mn,mx)\")\nmodel.add(\"ν ~ Exponential(29,offset=1)\")\nmodel.add(\"res_drug ~ StudentT(ν,drug-μ_drug,σ_drug,sum=True)\")\nmodel.add(\"res_placebo ~ StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)\")\n\npooled=np.concatenate([drug,placebo])\nS=mean(pooled)\nM=std(pooled)                      \nmodel.extra(S=S,M=M,mn=0.001*S,mx=1000*S)\n\nmodel.initialize()\nmodel\n\n\nParameters\n----------\n    {'μ_drug': μ_drug, 'μ_placebo': μ_placebo, 'σ_drug': σ_drug, 'σ_placebo': σ_placebo, 'ν': ν, 'res_drug': res_drug, 'res_placebo': res_placebo}\nExtra\n-----\n    ['S', 'M', 'mn', 'mx']\nData\n----\n    ['drug', 'placebo']\nPrior\n-----\n    ['μ_drug ~ Normal(M,1000*S)', 'μ_placebo ~ Normal(M,1000*S)', 'σ_drug ~ Uniform(mn,mx)', 'σ_placebo ~ Uniform(mn,mx)', 'ν ~ Exponential(29,offset=1)']\nLikelihood\n----------\n    ['res_drug ~ StudentT(ν,drug-μ_drug,σ_drug,sum=True)', 'res_placebo ~ StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)']\n        \n\n\n\nprint(model.make_func())\n\ndef _lnprior(θ,slices,extra={}):\n    S=extra['S']\n    M=extra['M']\n    mn=extra['mn']\n    mx=extra['mx']\n    μ_drug=θ[slices.μ_drug]\n    μ_placebo=θ[slices.μ_placebo]\n    σ_drug=θ[slices.σ_drug]\n    σ_placebo=θ[slices.σ_placebo]\n    ν=θ[slices.ν]\n\n    _value=0\n\n    _value+=Normal(M,1000*S)(μ_drug)\n    _value+=Normal(M,1000*S)(μ_placebo)\n    _value+=Uniform(mn,mx)(σ_drug)\n    _value+=Uniform(mn,mx)(σ_placebo)\n    _value+=Exponential(29,offset=1)(ν)\n\n    return _value\n\n\ndef _lnlikelihood(θ,data,slices,extra={}):\n    S=extra['S']\n    M=extra['M']\n    mn=extra['mn']\n    mx=extra['mx']\n    drug=data['drug']\n    placebo=data['placebo']\n\n    μ_drug=θ[slices.μ_drug]\n    μ_placebo=θ[slices.μ_placebo]\n    σ_drug=θ[slices.σ_drug]\n    σ_placebo=θ[slices.σ_placebo]\n    ν=θ[slices.ν]\n\n    res_drug=θ[slices.res_drug]\n    res_placebo=θ[slices.res_placebo]\n\n    _value=0\n\n    _value+=StudentT(ν,drug-μ_drug,σ_drug,sum=True)(res_drug)\n    _value+=StudentT(ν,placebo-μ_placebo,σ_placebo,sum=True)(res_placebo)\n\n    return _value.sum()"
  }
]