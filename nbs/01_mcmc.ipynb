{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d58a583-3da7-49f3-ae35-ef861fd244cf",
   "metadata": {},
   "source": [
    "## MCMC part of the libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5026e2-7356-4282-a021-c92e7ae6b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b92e2a-fd6c-437e-8128-b6887e10169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b84ab4-1a87-4ce3-9f2c-f4185f33e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pylab import *\n",
    "import emcee\n",
    "import warnings\n",
    "from scipy.special import gammaln,gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69180eb8-26ee-41e6-aed6-7f83d001fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import time\n",
    "\n",
    "def time2str(tm):\n",
    "    \n",
    "    frac=tm-int(tm)\n",
    "    tm=int(tm)\n",
    "    \n",
    "    s=''\n",
    "    sc=tm % 60\n",
    "    tm=tm//60\n",
    "    \n",
    "    mn=tm % 60\n",
    "    tm=tm//60\n",
    "    \n",
    "    hr=tm % 24\n",
    "    tm=tm//24\n",
    "    dy=tm\n",
    "\n",
    "    if (dy>0):\n",
    "        s=s+\"%d d, \" % dy\n",
    "\n",
    "    if (hr>0):\n",
    "        s=s+\"%d h, \" % hr\n",
    "\n",
    "    if (mn>0):\n",
    "        s=s+\"%d m, \" % mn\n",
    "\n",
    "\n",
    "    s=s+\"%.2f s\" % (sc+frac)\n",
    "\n",
    "    return s\n",
    "\n",
    "def timeit(reset=False):\n",
    "    global _timeit_data\n",
    "    try:\n",
    "        _timeit_data\n",
    "    except NameError:\n",
    "        _timeit_data=time.time()\n",
    "\n",
    "    if reset:\n",
    "        _timeit_data=time.time()\n",
    "\n",
    "    else:\n",
    "        return time2str(time.time()-_timeit_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a954bb-302a-428e-ac7b-9b36fa3e9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def histogram(y,bins=50,plot=True):\n",
    "    N,bins=np.histogram(y,bins)\n",
    "    \n",
    "    dx=bins[1]-bins[0]\n",
    "    if dx==0.0:  #  all in 1 bin!\n",
    "        val=bins[0]\n",
    "        bins=np.linspace(val-abs(val),val+abs(val),50)\n",
    "        N,bins=np.histogram(y,bins)\n",
    "    \n",
    "    dx=bins[1]-bins[0]\n",
    "    x=bins[0:-1]+(bins[1]-bins[0])/2.0\n",
    "    \n",
    "    y=N*1.0/np.sum(N)/dx\n",
    "    \n",
    "    if plot:\n",
    "        py.plot(x,y,'o-')\n",
    "        yl=py.gca().get_ylim()\n",
    "        py.gca().set_ylim([0,yl[1]])\n",
    "        xl=py.gca().get_xlim()\n",
    "        if xl[0]<=0 and xl[0]>=0:    \n",
    "            py.plot([0,0],[0,yl[1]],'k--')\n",
    "\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc091eb-b9d1-4688-9450-fc381b6366ee",
   "metadata": {},
   "source": [
    "## Distribution Log Likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099c4f7-cf12-4ce2-9f27-6a9313f1eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from scipy.stats import distributions as D\n",
    "\n",
    "def Normal(μ,σ,sum=False):\n",
    "    \n",
    "    def _Normal(x):\n",
    "        try:\n",
    "            N=len(x)\n",
    "        except TypeError:\n",
    "            N=1\n",
    "\n",
    "        values=-0.5*(x-μ)**2/σ**2 - 0.5*np.log(σ**2)-0.5*np.log(2*np.pi)\n",
    "        \n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "        \n",
    "    return _Normal\n",
    "\n",
    "def init_Normal(μ,σ,sum=False):\n",
    "    \n",
    "    def _init_Normal(nwalkers):\n",
    "        \n",
    "        values=np.random.randn(nwalkers)*σ+μ\n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "        \n",
    "    return _init_Normal\n",
    "\n",
    "def Uniform(mn,mx,sum=False):\n",
    "    \n",
    "    def _Uniform(x):\n",
    "        try:\n",
    "            N=len(x)\n",
    "            \n",
    "            if sum:\n",
    "                if any(x<mn):\n",
    "                    return -np.inf\n",
    "                if any(x>mx):\n",
    "                    return -np.inf\n",
    "                \n",
    "            values=np.log(1.0/(mx-mn))\n",
    "            \n",
    "            if sum:\n",
    "                return values.sum()\n",
    "            else:\n",
    "                return values\n",
    "            \n",
    "        except TypeError:\n",
    "            N=1\n",
    "\n",
    "            if mn < x < mx:\n",
    "                return np.log(1.0/(mx-mn))\n",
    "            return -np.inf\n",
    "        \n",
    "        \n",
    "    return _Uniform\n",
    "\n",
    "\n",
    "def init_Uniform(mn,mx,sum=False):\n",
    "    \n",
    "    def _init_Uniform(x):\n",
    "       \n",
    "        values=np.random.rand(nwalkers)*(mx-mn)+mn\n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "    \n",
    "        \n",
    "    return _init_Uniform\n",
    "\n",
    "\n",
    "def Exponential(scale,offset=0,sum=False):\n",
    "    \n",
    "    def _Exponential(x):\n",
    "        try:\n",
    "            N=len(x)\n",
    "            \n",
    "            if sum:\n",
    "                if any(x<offset):\n",
    "                    return -np.inf\n",
    "                if any(x>mx):\n",
    "                    return -np.inf\n",
    "                \n",
    "            values=-np.log(scale)-(x-offset)/scale \n",
    "            \n",
    "            if sum:\n",
    "                return values.sum()\n",
    "            else:\n",
    "                return values\n",
    "            \n",
    "        except TypeError:\n",
    "            N=1\n",
    "\n",
    "            if x<=offset:\n",
    "                return -np.inf\n",
    "            \n",
    "            return -np.log(scale)-(x-offset)/scale            \n",
    "            \n",
    "        \n",
    "        \n",
    "    return _Exponential\n",
    "\n",
    "\n",
    "def StudentT(df,mu,sd,sum=False):\n",
    "    \n",
    "    def _StudentT(x):\n",
    "        \n",
    "        t=(x-mu)/float(sd)\n",
    "        \n",
    "        try:\n",
    "            N=len(x)            \n",
    "        except TypeError:\n",
    "            N=1\n",
    "\n",
    "        values=N*(gammaln((df+1)/2.0)-0.5*log(df*np.pi)-gammaln(df/2.0)-np.log(sd))+(-(df+1)/2.0)*np.log(1+t**2/df)\n",
    "        \n",
    "        if any(np.isnan(values)):\n",
    "            raise ValueError('NaN in StudentT',df,mu,sd)\n",
    "            \n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "        \n",
    "        \n",
    "    return _StudentT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def HalfNormal(μ,σ,sum=False):\n",
    "    \n",
    "    def _Normal(x):\n",
    "        try:\n",
    "            N=len(x)\n",
    "            if any(x<0):\n",
    "                return -np.inf\n",
    "        except TypeError:\n",
    "            N=1\n",
    "            if x<0:\n",
    "                return -np.inf\n",
    "            \n",
    "        values=-0.5*(x-μ)**2/σ**2 - 0.5*np.log(σ**2)-0.5*np.log(2*np.pi)\n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "        \n",
    "    return _Normal\n",
    "\n",
    "\n",
    "def Jeffreys(sum=False):\n",
    "    \n",
    "    def _Jeffreys(x):\n",
    "        if x>0.0:\n",
    "            values=-np.log(x)\n",
    "        else:\n",
    "            values=-np.inf\n",
    "\n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values    \n",
    "        \n",
    "    return _Jeffreys\n",
    "\n",
    "\n",
    "def init_Jeffreys(mn,mx,sum=False):\n",
    "    \n",
    "    def _init_Jeffreys(x):\n",
    "       \n",
    "        values=np.random.rand(nwalkers)*2\n",
    "        if sum:\n",
    "            return np.sum(values)\n",
    "        else:\n",
    "            return values\n",
    "    \n",
    "        \n",
    "    return _init_Jeffreys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b43e3-0d98-4f06-b9bf-4bcbce354298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Normal(object):\n",
    "    def __init__(self,mean=0,std=1,sum=False):\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.sum=sum\n",
    "        \n",
    "    @property\n",
    "    def D(self):\n",
    "        return D.norm(self.mean,self.std)\n",
    "\n",
    "    def rand(self,*args):\n",
    "        return np.random.randn(*args)*self.std+self.mean\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return lognormalpdf(x,self.mean,self.std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3cfeb-4b7c-4f07-b9ac-8305682b3288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25edfb4e-85c9-4446-8cf7-5702667efb51",
   "metadata": {},
   "source": [
    "## Main MCMC Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb18e10-adba-49ea-abee-5b1d84c510fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameter(object):\n",
    "    \n",
    "    def __init__(self,eqn,initial_value=None):\n",
    "        self.eqn=eqn\n",
    "        name,rest=eqn.split('~')\n",
    "        self.name=name.strip()\n",
    "        self.rest=rest.strip()\n",
    "        self.length=1\n",
    "        self.lower=-np.inf\n",
    "\n",
    "        self.distribution=exec(self.rest)\n",
    "        self.distribution_name=self.rest\n",
    "        \n",
    "        if 'Jeffreys' in self.rest:\n",
    "            self.lower=0.0\n",
    "            if initial_value is None:\n",
    "                self.initial_value=1.0\n",
    "\n",
    "        if 'Exponential' in self.rest:\n",
    "            self.lower=0.0\n",
    "            if initial_value is None:\n",
    "                self.initial_value=1.0\n",
    "                \n",
    "        print(\"rest bb\",self.rest)\n",
    "        print(\"name bb\",self.name)\n",
    "                \n",
    "        if initial_value is None:\n",
    "            self.initial_value=0.0\n",
    "        else:\n",
    "            self.initial_value=initial_value\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "        \n",
    "class StatsModel(object):\n",
    "    def __init__(self):\n",
    "        self.parameters={}\n",
    "        self.data={}\n",
    "        self.prior_parameters=[]\n",
    "        self.likelihood_parameters=[]\n",
    "        self.nwalkers=100\n",
    "        self.sampler=None\n",
    "        self.slices=None\n",
    "        self.burn_percentage=0.25\n",
    "        self.warnings=[]\n",
    "        self.last_pos=None\n",
    "        self.extra_params={}\n",
    "    \n",
    "    \n",
    "    def add_data(self,**kwargs):\n",
    "        self.data.update(**kwargs) \n",
    "        \n",
    "\n",
    "    def extra(self,**kwargs):\n",
    "        for key in kwargs:\n",
    "            self.extra_params[key]=kwargs[key]\n",
    "        \n",
    "        \n",
    "    def add(self,eqn):\n",
    "        from io import StringIO\n",
    "        import tokenize\n",
    "        \n",
    "        param=Parameter(eqn)\n",
    "        self.parameters[param.name]=param\n",
    "        \n",
    "        tokens=[token[1] for token in tokenize.generate_tokens(StringIO(eqn).readline) if token[1]]\n",
    "        found=False\n",
    "        found_key=None\n",
    "        for key in self.data:\n",
    "            if key in tokens:\n",
    "                found=True\n",
    "                found_key=key\n",
    "                \n",
    "        if found:\n",
    "            self.likelihood_parameters.append(param)\n",
    "            if 'sum' in eqn:\n",
    "                self.likelihood_parameters[-1].length=1\n",
    "            else:\n",
    "                self.likelihood_parameters[-1].length=len(self.data[found_key])\n",
    "                \n",
    "        else:\n",
    "            self.prior_parameters.append(param)\n",
    "                \n",
    "                \n",
    "        \n",
    "    def __repr__(self):\n",
    "        S=\"\"\"\n",
    "Parameters\n",
    "----------\n",
    "    %s\n",
    "Extra\n",
    "-----\n",
    "    %s\n",
    "Data\n",
    "----\n",
    "    %s\n",
    "Prior\n",
    "-----\n",
    "    %s\n",
    "Likelihood\n",
    "----------\n",
    "    %s\n",
    "        \"\"\" % (self.parameters,list(self.extra_params.keys()),list(self.data.keys()),\n",
    "               [param.eqn for param in self.prior_parameters],\n",
    "               [param.eqn for param in self.likelihood_parameters]) \n",
    "        \n",
    "        return S\n",
    "    \n",
    "    def initialize(self):\n",
    "        from collections import namedtuple\n",
    "        self.make_func()\n",
    "        \n",
    "        names=','.join(self.parameters)\n",
    "        slicetuple = namedtuple(\"slicetuple\", names)\n",
    "        lengths=cumsum([0]+[len(self.parameters[key]) for key in self.parameters])\n",
    "        slices={}\n",
    "        for i,key in enumerate(self.parameters):\n",
    "            slices[key]=np.s_[lengths[i]:lengths[i+1]]\n",
    "        self.slices=slicetuple(**slices)\n",
    "        self.parameter_length=sum([len(self.parameters[key]) for key in self.parameters])\n",
    "        \n",
    "    def set_initial_values(self,method='ball',**kwargs):\n",
    "        N=300\n",
    "        ndim=self.parameter_length\n",
    "        nwalkers=self.nwalkers\n",
    "\n",
    "        if method=='ball':\n",
    "            print(\"Setting Center Cluster...\")\n",
    "            center=zeros(ndim)\n",
    "            for i,key in enumerate(self.parameters):\n",
    "                center[self.slices.__getattribute__(key)]=self.parameters[key].initial_value\n",
    "            \n",
    "            self.last_pos=emcee.utils.sample_ball(center, \n",
    "                            0.05*center+1e-4, size=nwalkers)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"done.\")\n",
    "            \n",
    "        elif method=='prior':\n",
    "        \n",
    "            self.sampler = emcee.EnsembleSampler(self.nwalkers, ndim, \n",
    "                                                 self._lnprior,args=(self.slices,self.extra_params,))\n",
    "\n",
    "#            pos=self._init_prior(nwalkers,ndim,self.data,self.slices,self.extra_params)\n",
    "            \n",
    "            \n",
    "            pos=np.zeros((nwalkers,ndim))\n",
    "            for i,key in enumerate(self.parameters):\n",
    "                pos[:,self.slices[i]]=np.random.randn(nwalkers,len(self.parameters[key]))*10\n",
    "                pos[:,self.slices[i]][pos[:,self.slices[i]]<=self.parameters[key].lower]=self.parameters[key].lower\n",
    "\n",
    "\n",
    "            self.initial_pos=pos.copy()\n",
    "            timeit(reset=True)\n",
    "            print(\"Sampling Prior...\")\n",
    "\n",
    "            with warnings.catch_warnings(record=True) as warning_list:\n",
    "                # Cause all warnings to always be triggered\n",
    "                #warnings.simplefilter(\"always\")\n",
    "                # Call your function that issues a warning        \n",
    "                self.sampler.run_mcmc(pos, N,**kwargs)\n",
    "\n",
    "            self.warnings.extend(warning_list)\n",
    "\n",
    "            print(\"Done.\")\n",
    "            print( timeit())\n",
    "            \n",
    "            # assign the median back into the simulation values\n",
    "            self.burn()\n",
    "            self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "\n",
    "            self.last_pos=self.sampler.chain[:,-1,:]\n",
    "            \n",
    "            \n",
    "        elif method=='samples':\n",
    "            print(\"Samples\")\n",
    "            lower,upper=np.percentile(self.samples, [16,84],axis=0)            \n",
    "            subsamples=self.samples[((self.samples>=lower) & (self.samples<=upper)).all(axis=1),:]\n",
    "            idx=np.random.randint(subsamples.shape[0],size=self.last_pos.shape[0])\n",
    "            self.last_pos=subsamples[idx,:]            \n",
    "        elif method=='median':            \n",
    "            vals=self.median_values\n",
    "            self.last_pos=emcee.utils.sample_ball(vals, \n",
    "                            0.05*vals+1e-4, size=self.nwalkers)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: %s\" % method)\n",
    "            \n",
    "        \n",
    "    def burn(self,burn_percentage=None):\n",
    "        if not burn_percentage is None:\n",
    "            self.burn_percentage=burn_percentage\n",
    "            \n",
    "        if self.burn_percentage>1:\n",
    "            self.burn_percentage/=100.0\n",
    "\n",
    "        burnin = int(self.sampler.chain.shape[1]*self.burn_percentage)  # burn 25 percent\n",
    "        ndim=self.parameter_length\n",
    "        self.samples = self.sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "        \n",
    "    def run_mcmc(self,N,repeat=1,**kwargs):\n",
    "        ndim=self.parameter_length\n",
    "        nwalkers=self.nwalkers\n",
    "        \n",
    "        if self.last_pos is None:\n",
    "            self.set_initial_values('prior')\n",
    "        \n",
    "\n",
    "        for i in range(repeat):        \n",
    "            timeit(reset=True)\n",
    "            self.sampler = emcee.EnsembleSampler(self.nwalkers, ndim, self,)\n",
    "\n",
    "            if repeat==1:\n",
    "                print(\"Running MCMC...\")\n",
    "            else:\n",
    "                print(\"Running MCMC %d/%d...\" % (i+1,repeat))\n",
    "\n",
    "            self.sampler.run_mcmc(self.last_pos, N,**kwargs)\n",
    "            print(\"Done.\")\n",
    "            print (timeit())\n",
    "\n",
    "            if repeat>1:\n",
    "                self.burn()\n",
    "                self.set_initial_values('samples')  # reset using the 16-84 percentile values from the samples\n",
    "\n",
    "\n",
    "        # assign the median back into the simulation values\n",
    "        self.burn()\n",
    "        self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "        theta=self.median_values\n",
    "\n",
    "        self.last_pos=self.sampler.chain[:,-1,:]\n",
    "    \n",
    "        \n",
    "        \n",
    "    def plot_chains(self,*args,**kwargs):\n",
    "        import pylab as py\n",
    "        \n",
    "        if not args:\n",
    "            args=[key for key in self.parameters if len(self.parameters[key])==1]\n",
    "        else:\n",
    "            for arg in args:\n",
    "                assert arg in self.parameters\n",
    "                \n",
    "        L=sum([len(self.parameters[key]) for key in args])\n",
    "\n",
    "        figsize=rcParams['figure.figsize']\n",
    "        figsize[1]=5/8*figsize[0]*L  # make square\n",
    "        figsize=kwargs.pop('figsize',figsize)\n",
    "        \n",
    "        print(\"figsize\",figsize)\n",
    "        fig, axes = py.subplots(len(args), 1, sharex=True, figsize=figsize)\n",
    "        try:  # is it iterable?\n",
    "            axes[0]\n",
    "        except TypeError:\n",
    "            axes=[axes]\n",
    "\n",
    "\n",
    "        labels=[]\n",
    "        count=0\n",
    "        for key in args:\n",
    "            s=self.slices.__getattribute__(key)\n",
    "            sub_sample=self.sampler.chain[:, :, s]\n",
    "            for i in range(len(self.parameters[key])):\n",
    "                sample=sub_sample[:, :, i].T\n",
    "                ax=axes[count]\n",
    "                ax.plot(sample, color=\"k\", alpha=0.2,**kwargs)\n",
    "                \n",
    "                if len(self.parameters[key])==1:\n",
    "                    ax.set_ylabel(f'{key}' )\n",
    "                else:\n",
    "                    ax.set_ylabel(f'{key}$_{i}$')\n",
    "\n",
    "\n",
    "                \n",
    "                count+=1\n",
    "            \n",
    "        \n",
    "    def _lnposterior(self,θ):\n",
    "        _value=0\n",
    "        _value+=self._lnprior(θ,self.slices,self.extra_params)\n",
    "        _value+=self._lnlikelihood(θ,self.data,self.slices,self.extra_params)\n",
    "        \n",
    "        return np.sum(_value)\n",
    "    \n",
    "    def __call__(self,θ):\n",
    "        return self._lnposterior(θ)\n",
    "    \n",
    "    def percentiles(self,p=[16, 50, 84],*args):\n",
    "        if not args:\n",
    "            args=[key for key in self.parameters if len(self.parameters[key])==1]\n",
    "        else:\n",
    "            for arg in args:\n",
    "                assert arg in self.parameters\n",
    "        \n",
    "        self.median_values=np.percentile(self.samples,50,axis=0)\n",
    "        \n",
    "        result={}\n",
    "        for key in args:\n",
    "            s=self.slices.__getattribute__(key)\n",
    "            sub_sample=self.samples[:,s]\n",
    "            result[key]=np.percentile(sub_sample,[16,50,84],axis=0)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def best_estimates(self,*args):\n",
    "        return self.percentiles(p=[16, 50, 84],*args)\n",
    "\n",
    "\n",
    "    def plot_distributions(self,*args,**kwargs):\n",
    "        if not args:\n",
    "            args=[key for key in self.parameters if len(self.parameters[key])==1]\n",
    "        else:\n",
    "            for arg in args:\n",
    "                assert arg in self.parameters\n",
    "\n",
    "        result=[]\n",
    "        for key in args:\n",
    "            s=self.slices.__getattribute__(key)\n",
    "            sub_sample=self.samples[:,s]\n",
    "            for i in range(len(self.parameters[key])):\n",
    "                sample=sub_sample[:, i].ravel()\n",
    "            \n",
    "                figure(figsize=(12,4))\n",
    "\n",
    "                x,y=histogram(sample,bins=200,plot=False)\n",
    "                plot(x,y,'.-')\n",
    "                fill_between(x,y,facecolor='blue', alpha=0.2)\n",
    "\n",
    "                HDI=np.percentile(sample, [2.5, 50, 97.5],axis=0)\n",
    "                yl=gca().get_ylim()\n",
    "                text((HDI[0]+HDI[2])/2, 0.15*yl[1],'95% HDI', ha='center', va='center',fontsize=12)\n",
    "                plot(HDI,[yl[1]*.1,yl[1]*.1,yl[1]*.1],'k.-',linewidth=1)\n",
    "                for v in HDI:\n",
    "                    if v<0.005:\n",
    "                        text(v, 0.05*yl[1],'%.3g' % v, ha='center', va='center', \n",
    "                             fontsize=12)\n",
    "                    else:\n",
    "                        text(v, 0.05*yl[1],'%.3f' % v, ha='center', va='center', \n",
    "                             fontsize=12)\n",
    "\n",
    "                ylabel(r'$p(%s|{\\rm data})$' % key)\n",
    "                if len(self.parameters[key])==1:\n",
    "                    gca().set_xlabel(f'{key}' )\n",
    "                else:\n",
    "                    gca().set_xlabel(f'{key}$_{i}$')\n",
    "    \n",
    "                result.append((key,i,HDI))\n",
    "        \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631487c9-d941-45ad-9888-22665727ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def make_func(self:StatsModel):\n",
    "    s=\"def _lnprior(θ,slices,extra={}):\\n\"\n",
    "\n",
    "    if self.extra_params:\n",
    "        for key in self.extra_params:\n",
    "            s+=f\"    {key}=extra['{key}']\\n\"\n",
    "\n",
    "    for param in self.prior_parameters:\n",
    "        name=param.name\n",
    "        s+=f\"    {name}=θ[slices.{name}]\\n\" \n",
    "\n",
    "    s+=\"\\n    _value=0\\n\\n\"\n",
    "\n",
    "    for param in self.prior_parameters:\n",
    "        name=param.name\n",
    "        rest=param.rest\n",
    "        s+=f\"    _value+={rest}({name})\\n\" \n",
    "\n",
    "\n",
    "    s+=\"\\n    return _value\\n\"\n",
    "\n",
    "    s+=\"\\n\\n\"\n",
    "\n",
    "\n",
    "    s+=\"def _init_prior(nwalkers,ndim,data,slices,extra={}):\\n\"\n",
    "#     s+=\"\\n    _value=None\\n\"\n",
    "    \n",
    "#     s+=\"\\n    return _value\\n\"\n",
    "#     s+=\"\\n\\n\"\n",
    "\n",
    "    if self.extra_params:\n",
    "        for key in self.extra_params:\n",
    "            s+=f\"    {key}=extra['{key}']\\n\"\n",
    "            \n",
    "    for key in self.data:\n",
    "        s+=f\"    {key}=data['{key}']\\n\"\n",
    "    s+=\"\\n\"\n",
    "            \n",
    "\n",
    "    s+=f\"    _pos=np.zeros((nwalkers,ndim))\\n\" \n",
    "\n",
    "    for param in self.prior_parameters:\n",
    "        name=param.name\n",
    "        rest=param.rest\n",
    "        s+=f\"    {name}=_pos[:,slices.{name}]=init_{rest}(nwalkers)\\n\" \n",
    "\n",
    "    for param in self.likelihood_parameters:\n",
    "        name=param.name\n",
    "        rest=param.rest\n",
    "        s+=f\"    {name}=_pos[:,slices.{name}]=init_{rest}(nwalkers)\\n\" \n",
    "\n",
    "\n",
    "\n",
    "    s+=\"\\n    return _pos\\n\"\n",
    "\n",
    "    s+=\"\\n\\n\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    s+=\"def _lnlikelihood(θ,data,slices,extra={}):\\n\"\n",
    "\n",
    "    if self.extra_params:\n",
    "        for key in self.extra_params:\n",
    "            s+=f\"    {key}=extra['{key}']\\n\"\n",
    "\n",
    "    for key in self.data:\n",
    "        s+=f\"    {key}=data['{key}']\\n\"\n",
    "    s+=\"\\n\"\n",
    "\n",
    "    for param in self.prior_parameters:\n",
    "        name=param.name\n",
    "        s+=f\"    {name}=θ[slices.{name}]\\n\" \n",
    "    s+=\"\\n\"\n",
    "    for param in self.likelihood_parameters:\n",
    "        name=param.name\n",
    "        s+=f\"    {name}=θ[slices.{name}]\\n\" \n",
    "\n",
    "    s+=\"\\n    _value=0\\n\\n\"\n",
    "\n",
    "    for param in self.likelihood_parameters:\n",
    "        name=param.name\n",
    "        rest=param.rest\n",
    "        s+=f\"    _value+={rest}({name})\\n\"\n",
    "\n",
    "    s+=\"\\n    return _value.sum()\\n\"\n",
    "\n",
    "\n",
    "    self.function_str=s\n",
    "\n",
    "    \n",
    "    \n",
    "    exec(s)\n",
    "\n",
    "    self._init_prior=locals()['_init_prior']\n",
    "    self._lnprior=locals()['_lnprior']\n",
    "    self._lnlikelihood=locals()['_lnlikelihood']\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f337abb-e50e-4a28-b552-35a514bc244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c3989-6ccd-41a5-80db-90e445ef9af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59d2b7-ed67-47dd-87d9-0267dc00fab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
